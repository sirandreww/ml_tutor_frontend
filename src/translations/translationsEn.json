{
    "next": "Next",
    "back": "Back",
    "finish": "Finish",
    "reset": "Reset",
    "homepage":{
        "intro":"Understand how Machine Learning works by using 3D animation and simple explanations.",
        "get_started_btn":"Get started",
        "first_paper_header":"2D/3D visual representation",
        "first_paper_text":"Understand the underlying mathematics using visual methods.",
        "second_paper_header":"Step by Step demonstrations",
        "second_paper_text":"We take you through the learning process with no sudden jumps along the way!",
        "third_paper_header":"Track your progress",
        "third_paper_text":"Never lose track of where you are.",
        "fourth_paper_header":"Easy to understand",
        "fourth_paper_text":"Finally get that one topic you could never master!"
    },

    "algorithms":{
        "algos": "Algorithms",
        "get_started":"How to Get started?",
        "choose_alg":"Simply choose one of the following algorithms and start learning!"
    },

    "cards":{
        "main_algs":"Main Algorithms",
        
        "linear_regression":{
            "text":"Learn the Linear Regression Algorithm",
            "info":"This algorithm finds the closest linear line to all the points",
            "label":"Linear Regression"
        },
        
        "gradient_descent":{
            "text":"Learn the Gradient Descent Algorithm",
            "info":"This algorithm helps in finiding the minimal point of a function",
            "label":"Gradiant Descent"
        },

        "knn":{
            "text":"Learn the K-Nearest Neighbors Algorithm",
            "info":"This algorithm predicts the type of an object based on its k-nearest-neighbors",
            "label":"K Nearest Neighbors"
        },

        "neural_networks":{
            "text":"Learn the Neural Networks Algorithm",
            "info":"This algorithm predicts the right answer",
            "label":"Neural Networks"
        },

        "logistic_regression":{
            "text":"Learn the Logistic Regression Algorithm",
            "info":"This algorithm finds the closest line to all the points",
            "label":"Logistic Regression"
        }

        

    },

    "gd":{
        "end":"All steps completed - you're finished",
        "description":"Gradient descent is an iterative algorithm for finding a local minimum.\nIt starts at a given point and the idea is to take repeated steps in the opposite direction of the gradient (derivative) of the function at the current point.",
        "idea":"In each step the algorithm calculates the derivative of the current point and based on that it calculate the next point.\nFirst we will introduce a Hyper-Parameter called alpha. Alpha holds a number which is responsible for the step size.",
        "example_1":"Let us take for example",
        "example_2":"as the function and",
        "example_3":"as the starting point.",
        "gd_two_vars":"Now let us see how Gradient Descent handles functions with 2 variables!",

        "steps":"The first 10 steps the algorithm takes are shown in the following animation:",
        "how":"How does the algorithm achieve this?",
        "defs":"Some definitions:",
        "almost_descr":"Almost the same as before!",

        "point_vals":{
            "x_val":"the x value of the point.",
            "y_val":"the y value of the point.",
            "x_val_new":"the x value of the new point.",
            "y_val_new":"the y value of the new point.",
            "z_val":"the z value of the point."
        },

        "derivatives":{
            "description":"the derivative of f.",
            "derivative_val_x":"the value of the derivative at x.",
            "f_by_x":"the derivative of f by x variable (consider y as a constant).",
            "f_by_y":"the derivative of f by y variable (consider x as a constant).",
            "val_f_by_x":"the value of the derivative by x at (x, y).",
            "val_f_by_y":"the value of the derivative by y at (x, y)."
        },

        "hyperparameter":"the Hyper-parameter that dictates step size.",
        "foreach_step":"In each step the algorithm does the following:",
        "calc":"calculate",
        "apply":"Apply",
        
        "slides":{
            "alpha":"alpha",
            "starting_point":"Starting point",
            "derivative":"the derivative of the function is"
        },
        "tasks" : {
            "1d_int": "1D Introduction",
            "1d_vis": "Visualization",
            "1d_sbs": "Step By Step",
            "1d_hyp": "Hyper-Parameter",
            "2d_int": "2D Introduction",
            "2d_vis": "Visualization",
            "2d_sbs": "Step By Step",
            "2d_hyp": "Hyper-Parameter"
        },

        "enter_func":"Enter a function (can be any function you want but the variable must be x), Hyper-Parameter and set the starting point.\nHit the play button to start the animation, you can also pause it and zoom in the graph by clicking the pause button or clear everything using the X button.",
        "try_calc":"Try to calculate the value of each variable as the algorithm does (2 decimal points).\nEach click on the arrow will draw the next/previous step",
        "search_alpha":"Search for the best alpha which gets to the minimum with the least amount of steps.",
        "you_try":"Try it yourself! Just like before the variables must be x and y.",
        "challenge":"Challenge yourself and calculate each step."
    },

    "logreg": {
        "description":"In statistics, the logistic model (or logit model) is used to model the probability of a certain class or event taking place, such as the probability of a team winning, of a patient being healthy, etc.",
    
        "tasks" : {
            "log_reg_step_1_title": "Introduction",
            "log_reg_step_2_title": "Exercise 1",
            "log_reg_step_3_title": "Vector Representation",
            "log_reg_step_4_title": "Multi-Inputs",
            "log_reg_step_5_title": "Train A Model",
            "log_reg_step_6_title": "Step By Step",
            "log_reg_step_7_title": "Hyper-Parameter"
        }
    },

    "lr": {
    
        "tasks" : {
            "1d_int": "Introduction",
            "1d_vis": "First Example",
            "p3_title": "Dynamic Model",
            "p4_title": "Analytical Excercise",
            "p5_title": "Calculation using Gradiant-Descent",
            "p6_title": "Gradiant Descent Excercise"
        }
    },


    "sign_in":{
        "login":"Sign in",
        "forgot_pass":"Forgot password?",
        "sign_up":"Don't have an account? Sign Up"
    },

    "footer":{
        "made_by":"Made by Technion Students!"
    },

    "list_items":{
        "sub_head":"Saved reports"
    },

    "task":"task"
}