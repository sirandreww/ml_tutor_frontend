{
    "next": "Next",
    "back": "Back",
    "finish": "Finish",
    "reset": "Reset",
    "tasks": "Tasks",
    "contact_us_page":{
        "intro":"Who are we?",
        "first_row":"We are thechnion students making this website as a part of a yearly project.",
        "second_row":"Our names are: Andrew, Aseel, David, Eden and Ofik..",
        "third_row":"What is this website?",
        "fourth_row":"This website is made to help primarily high school students in understanding and visulaizing algorithms in machine learning.",
        "fifth_row":"How can I report bugs or suggest features?",
        "sixth_row":"You can do so by sending us an email at:"
    },

    "homepage":{
        "intro":"Understand how Machine Learning works by using 3D animation and simple explanations.",
        "get_started_btn":"Get started",
        "first_paper_header":"2D/3D visual representation",
        "first_paper_text":"Understand the underlying mathematics using visual methods.",
        "second_paper_header":"Step by Step demonstrations",
        "second_paper_text":"We take you through the learning process with no sudden jumps along the way!",
        "third_paper_header":"Track your progress",
        "third_paper_text":"Never lose track of where you are.",
        "fourth_paper_header":"Easy to understand",
        "fourth_paper_text":"Finally get that one topic you could never master!"
    },

    "algorithms":{
        "algos": "Algorithms",
        "contact": "Contact Us",
        "get_started":"How to Get started?",
        "choose_alg":"Simply choose one of the following algorithms and start learning!",
        "cheat_sheet":"Cheat sheet for math function notation:",
        "function": "function",
        "notation": "notation"
    },

    "cards":{
        "main_algs":"Main Algorithms",
        
        "linear_regression":{
            "text":"Learn the Linear Regression Algorithm",
            "info":"This algorithm finds the closest linear line to all the points",
            "label":"Linear Regression"
        },
        
        "gradient_descent":{
            "text":"Learn the Gradient Descent Algorithm",
            "info":"This algorithm helps in finiding the minimal point of a function",
            "label":"Gradiant Descent"
        },

        "knn":{
            "text":"Learn the K-Nearest Neighbors Algorithm",
            "info":"This algorithm predicts the type of an object based on its k-nearest-neighbors",
            "label":"K Nearest Neighbors"
        },

        "neural_networks":{
            "text":"Learn the Neural Networks Algorithm",
            "info":"This algorithm predicts the right answer",
            "label":"Neural Networks"
        },

        "logistic_regression":{
            "text":"Learn the Logistic Regression Algorithm",
            "info":"This algorithm finds the closest line to all the points",
            "label":"Logistic Regression"
        }

        

    },

    "gd":{
        "end":"All steps completed - you're finished",
        "description":"Gradient descent is an iterative algorithm for finding a local minimum.\nIt starts at a given point and the idea is to take repeated steps in the opposite direction of the gradient (derivative) of the function at the current point.",
        "idea":"In each step the algorithm calculates the derivative of the current point and based on that it calculate the next point.\nFirst we will introduce a Hyper-Parameter called alpha. Alpha holds a number which is responsible for the step size.",
        "example_1":"Let us take for example",
        "example_2":"as the function and",
        "example_3":"as the starting point.",
        "gd_two_vars":"Now let us see how Gradient Descent handles functions with 2 variables!",

        "steps":"The first 10 steps the algorithm takes are shown in the following animation:",
        "how":"How does the algorithm achieve this?",
        "defs":"Some definitions:",
        "almost_descr":"Almost the same as before!",

        "point_vals":{
            "x_val":"the x value of the point.",
            "y_val":"the y value of the point.",
            "x_val_new":"the x value of the new point.",
            "y_val_new":"the y value of the new point.",
            "z_val":"the z value of the point."
        },

        "derivatives":{
            "description":"the derivative of f.",
            "derivative_val_x":"the value of the derivative at x.",
            "f_by_x":"the derivative of f by x variable (consider y as a constant).",
            "f_by_y":"the derivative of f by y variable (consider x as a constant).",
            "val_f_by_x":"the value of the derivative by x at (x, y).",
            "val_f_by_y":"the value of the derivative by y at (x, y)."
        },

        "hyperparameter":"the Hyper-parameter that dictates step size.",
        "foreach_step":"In each step the algorithm does the following:",
        "calc":"calculate",
        "apply":"Apply",
        
        "slides":{
            "alpha":"alpha",
            "starting_point":"Starting point",
            "derivative":"the derivative of the function is"
        },
        "tasks" : {
            "1d_int": "1D Introduction",
            "1d_vis": "Visualization",
            "1d_sbs": "Step By Step",
            "1d_hyp": "Hyper-Parameter",
            "2d_int": "2D Introduction",
            "2d_vis": "Visualization",
            "2d_sbs": "Step By Step",
            "2d_hyp": "Hyper-Parameter"
        },

        "enter_func":"Enter a function (can be any function you want but the variable must be x), Hyper-Parameter and set the starting point.\nHit the play button to start the animation, you can also pause it and zoom in the graph by clicking the pause button or clear everything using the X button.",
        "try_calc":"Try to calculate the value of each variable as the algorithm does (2 decimal points).\nEach click on the arrow will draw the next/previous step",
        "search_alpha":"Search for the best alpha which gets to the minimum with the least amount of steps.",
        "you_try":"Try it yourself! Just like before the variables must be x and y.",
        "challenge":"Challenge yourself and calculate each step."
    },

    "logreg": {
        "tasks" : {
            "log_reg_step_1_title": "Introduction",
            "log_reg_step_2_title": "Exercise 1",
            "log_reg_step_3_title": "Vector Representation",
            "log_reg_step_4_title": "Multi-Samples",
            "log_reg_step_5_title": "Train A Model",
            "log_reg_step_6_title": "Step By Step",
            "log_reg_step_7_title": "Hyper-Parameter"
        },

        "pages": {
            "intro_title": "Logistic Regression",
            "intro": {
                "description":"In statistics, the logistic model (or logit model) is used to model the probability of a certain class or event taking place, such as the probability of a team winning, of a patient being healthy, etc.",
                "weights": "Logistic regression is a classification algorithm. The parameters for this classifier are the weights ",
                "num": " and a number ",
                "vec": "The input for the classifier is an object with a vector of features ",
                "y": "The classifier calculates ",
                "y_def": ", which is the probability that the object belongs to the class \"1\" using the following calculation:",
                "sigmoid_fun_def": "Where the Sigmoid function is defined as ",
                "cal_prob": "The classifier will then predict that the class of the object is \"1\" if ",
                "demo": "Let's try to understand this even more with a demo, choose your weight and bias and test different values for x :",
                "example": "Now let's see the function of the classifier as defined by the weight and bias :",
                "task1": "Given w = 111 and b = 1, what value of x would result in the probability being 0.5?"
            },
            "ex1_title": "Logistic Regression Exercise 1",
            "ex1": {
                "line_1": "Now that we know the basics of linear regression, let's do an exercise together.",
                "line_2": "We are given images and 2 features for every image :",
                "red_avg": "the average value of the red pallet in the image.",
                "blue_avg": "the average value of the blue pallet in the image."
            },
            "vec_rep_title": "Logistic Regression Using Vectors",
            "vec_rep": {
                "expr": "The expression",
                "expr_simple": " can be simplified as the multiplication of 2 vectors",
                "alg_calc": "Thus the calculation done by the linear regression algorithm can be expressed as:",
                "sig_def": "Where the Sigmoid function is defined as ",
                "y_calc": "The classifier will then predict that the class of the object is \"1\" if",
                "demo": "Let's try to understand this even more with a demo, choose your weights and bias and test different values for x :",
                "graph": "Here is the graph that represents the classifier :"
            },
            "multi_samples_title": "Logistic Regression With Multiple Samples",
            "multi_samples": {
                "intro": "So far we have learned how the logistic regression classifies an input (with either with 1 feature or more),\nIn this page we will now learn how we can classifies multiple inputs in one time!",
                "vectors": "In other words we can transform multiple input vectors ",
                "matrix": " to\none huge matrix ",
                "Y": " which holds all the data (rows are the samples and columns are the feature for each sample),\nthen apply the sigmoid function on it and returns a vector ",
                "pred": " of predictions for each input",
                "samples_num": "the number of samples",
                "features_num": "the number of features",
                "task": "In this page we will have 3 samples which represents a color's RGB values,\nand we want to predict if the color is blue or not ( m = 3, n = 3) -",
                "weights": "Vector of weights (weight for each feature):",
                "b": "The Constant value:",
                "matrix_pres": "The data will be present in a matrix like this:",
                "sigmoid_cal": "The calculation of the sigmoid on this huge matrix is done as follows",
                "calculate": " Calculate",
                "add_b": " Add the constant b to each entry of the result vector - ",
                "apply": " Apply the sigmoid function on each entry of the previous vector - ",
                "get_Y": " Get ",
                "by_checking": " by checking if "
            },
            "training_title": "Logistic Regression Training",
            "training": {
                "intro": "So far we have learned how the logistic regression classifies an input (with either with 1 feature or more),\nIn this page we will now learn how we build such model, in other words we will learn how we find the best weights and b to have the highest accuracy!",
                "logReg_q": "First what is a Logistic Regression Model",
                "logReg_ans_p1": "A logistic regression model donated by ",
                "logReg_ans_p2": " where",
                "logReg_ans_w": " is the vector of weights",
                "logReg_ans_b": " is the constant",
                "acc_q": "First of all how we can measure an accuracy of such model",
                "acc_ans": "Answer: Cost Function (or Loss Function)\nWhich is a function that represents the error of our calculations.\nIf the returned value of this function is closer to 0 then the model is better and it predicts more correctly.\nIf the returned value of this function is more distant from 0 then the model is worst and it doesn't predict correctly.",
                "consider": "Consider having",
                "consider_x": " Matrix with multiple samples (m)",
                "consider_w": " Vector of weights (n)",
                "consider_b": " Constant",
                "consider_c": " The actual classifications for each sample",
                "calc_y": "Then we calculate the vector of predictions",
                "prev": "like Previously",
                "after": "After it we calculate the following Loss Function",
                "ci": " is the actual classification of the i'th sample",
                "yi": " is the prediction of the i'th sample",
                "ret_type": "This function returns a number which indicates how good is our model",
                "trainModel_q": "What do we mean by train a model",
                "trainModel_ans": "When we say train a model we mean that we get a lot of samples which are in form of a table like we have explained above\nand we want to search for the best ws and b!\nIn other words we want to minimize the Loss Function --- Gradiant Descent!!!\n",
                "above_inputs": "Consider having the same input as above",
                "additional_inputs": "Also we have the hyper-parameter of the Gradiant Descent",
                "defs": "Some Definitions",
                "loss_def": "The loss function mentioned above",
                "dwi_def": "The derivative of the Loss function by i'th weight, X_i is the i'th column of X",
                "dW_def": "The derivative of the Loss function by the weights",
                "dbi_def": "The derivative of the Loss function by the constant b for the i'th sample",
                "dB_def": "The derivative of the Loss function by the constant B on all samples",
                "init": "Initiate the following variables",
                "init_w": "vector of weights (entry for each weight)",
                "init_b": "The constant",
                "step": "In each step the Gradiant Descent does the following",
                "step_calculate": "Calculate",
                "step_apply": "Apply",
                "demo": "Let's try with a demo, insert following given data and their classifications",
                "demo_init": "The Algorithm will initiate the following data",
                "demo_itr_res": "The results of the 1st iteration are",
                "demo_final_res": "The final results"
            },
            "sbs_title": "Step By Step Training",
            "sbs": {
                "task": "In this task will learn calculate how we train a module step by step.",
                "itr_num": "Iteration number",
                "res": "Results",
                "calc": "Calculations",
                "final_res": "Final Results"
            },
            "hp_title": "Understanding Hyper Parameter Importance",
            "hp": {
                "intro": "In this task will learn how the alpha, number of iterations and the size of training batch affects the accuracy of our model.\nWe will take the Iris datasets which contains the following data of the Iris flower",
                "sp_length": "Sepal Length (in centimeters)",
                "sp_width": "Sepal Width (in centimeters)",
                "pe_length": "Petal Length (in centimeters)",
                "pe_width": "Petal Width (in centimeters)",
                "dataset": "The dataset contains 3 types of Iris flowers (for each type we have 50 samples)",
                "setosa": "Setosa",
                "versicolor": "Versicolor",
                "virginica": "Virginica",
                "task": "Please insert the desired alpha, number of iterations and the percentage of the dataset to be our training batch (the rest is the test batch),\nWe will calculate the accuracy of the trained model based on the input, try to find the best parameters!",
                "itr_num": "Number Of Iterations",
                "trn_per": "Train Percentage",
                "mdl_acc": "Accuracy",
                "mdl_loss": "Loss"
            }
        }
    },

    "lr": {
        "tasks" : {
            "1d_int": "Introduction",
            "1d_vis": "First Example",
            "p3_title": "Dynamic Model",
            "p4_title": "Analytical Excercise",
            "p5_title": "Calculation using Gradiant-Descent",
            "p6_title": "Gradiant Descent Excercise"
        },

        "title":"Linear regression",
        "examples_set":"Given a set of m examples",
        "x_vals":"sample values of the independent variable",
        "y_vals":"sample values of the dependent variable respectively",
        "description":"Linear regression is a mathematical method for finding the parameters of the relationship between an independent variable X and a dependent variable Y,\nassuming that the relationship between them is linear,\nwe would like to find an optimal regression model from the form",
        "opt_params":"How to find the optimal parameters of the model?",
        "min_params":"We take the parameters that minimize the sum of mean squared loss",
        "defs":"Some definitions",
        "x_mean_val":"the mean value of x",
        "y_mean_val":"the mean value of y",
        "analytic_sol":"So the analytical solution is",
        "p2_desc":"In this example we will try to predict the housing prices (in millions) according to the number of rooms.\nThe table contains data of housing prices. below, there are the parameters needed in order to evaluate the prediction of the model, the Regression function, and finally, the graph with the regression line.",
        "p3_desc":"It's time to see the model in action. \nAdd points and edit the values as you want, you'll see the parameters being calculated on the go\nand the Linear line which represents the model's predictions forms on the graph below.",
        "p4_desc":"Now it's your turn! you're given a partial table from the Iris Database, where X is the Sepal length, and Y is the Sepal width of the flower.\nYour mission is to calculate the parameters in order to form the correct model.\nBelow, you will see the correct model representation in blue, and your model will\nappear in red.\nGood Luck!"
    },


    "sign_in":{
        "login":"Sign in",
        "forgot_pass":"Forgot password?",
        "sign_up":"Don't have an account? Sign Up"
    },

    "footer":{
        "made_by":"Made by Technion Students!"
    },

    "list_items":{
        "sub_head":"Saved reports"
    },

    "task":"task"
}