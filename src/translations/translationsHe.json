{
    "next": "הבא",
    "back": "הקודם",
    "finish": "סיום",
    "reset": "שחזר",
    "tasks": "משימות",
    "contact_us_page":{
        "intro":"מי אנחנו?",
        "first_row":"אנחנו סטודנטים מהטכניון שיצרו את האתר כחלק מפרויקט שנתי",
        "second_row":"השמות שלנו הם: אנדרו, אציל, דוד, עדן ואופק",
        "third_row":"מה זה האתר הזה?",
        "fourth_row":"האתר הזה נוצר כדי לסייע לתלמידי תיכון להבין ולראות בצורה ויזואלית אלגוריתמים בלמידת מכונה",
        "fifth_row":"איך אוכל לדווח על תקלות או להציע פיצ'רים?",
        "sixth_row":"את או אתה יכולים לעשות זאת באמצעות שליחת מייל לכתובת הבאה:"
    },
    "homepage":{
        "intro":"להבין איך למידת מכונה מתבצעת בעזרת סמולציות ואנמציות בדו/תלת מימד והסברים פשוטים.",
        "get_started_btn":"להתחלה לחץ כאן",
        "first_paper_header":"ויזואליזציות ב -דו/תלת מימד",
        "first_paper_text":"להבין את המתמטיקה מאחורי האלגוריתמים בעזרת דברים ויזואלים.",
        "second_paper_header":"הדגמות שמתבצעות בצעדים.",
        "second_paper_text":"עוברים איתך על כל התהליך בלי קיצורי דרך!",
        "third_paper_header":"מעקב אחר התקדמות הלמידה שלך.",
        "third_paper_text": "לא תאבד את עקבותיך בלמידה של האלגוריתמים.",
        "fourth_paper_header":"קל להבנה",
        "fourth_paper_text": "סוף סוף תשלוט בנושאים שאתה מתקשה ללמוד!"
    },

    "algorithms":{
        "algos": "אלגורתמים",
        "contact": "יצירת קשר",
        "get_started": "איך להתחיל?",
        "choose_alg": "יש לבחור אחד מהאלגוריתמים שמעניינים אותך ולהתחיל ללמוד!",
        "cheat_sheet":"טבלת עזר לסימול פונקציות באתר:",
        "function": "פונקציה",
        "notation":"סימול"
    },

    "cards":{
        "main_algs":"אלגוריתמים עיקריים",
        
        "linear_regression":{
            "text": "תלמד את האלגוריתם linear regression.",
            "info":"האלגוריתם מוצא את הקו הלינארי הכי קרוב לכל הנקודות.",
            "label":"linear regression"
        },
        
        "gradient_descent":{
            "text":"תלמד את האלגוריתם Gradient Descent.",
            "info":"האלגוריתם הזה מוצא את המינימום של הפונקציה",
            "label":"Gradiant Descent"
        },

        "knn":{
            "text":"תלמד את האלגוריתם K Nearest Neighbors.",
            "info":"האלגוריתם חוזה את הסוג של האובייקט לפי K השכנים הכי קרובים אליו.",
            "label":"K Nearest Neighbors"
        },

        "neural_networks":{
            "text":"תלמד את האלגוריתם neural networks",
            "info":"האלגוריתם חוזה את התשובה הנכונה.",
            "label":"neural networks"
        },

        "logistic_regression":{
            "text":"תלמד את האלגוריתם logistic regression.",
            "info":"האלגוריתם מוצא את הקו הכי קרוב לכל הנקודות.",
            "label":"logistic regression"
        }

    },


    "gd":{
        "end": "סיימת את כל השלבים!",
        "description":"Gradient descent הוא אלגוריתם איטרטיבי למציאת מינימום מקומי.\nזה מתחיל בנקודה נתונה והרעיון הוא לעשות צעדים חוזרים ונשנים בכיוון ההפוך לשיפוע (נגזרת) של הפונקציה בנקודה הנוכחית.",
        "idea": "הרעיון מאחורי זה הוא לקחת צעדים בכיוונים מנוגדים מהנגזרת של הפונקציה בנקודה מסויימת.",
        "example_1":"בוא ניקח לדוגמא את הפונקציה",
        "example_2":"עם",
        "example_3":"כנקודת התחלה",
        "gd_two_vars":"כעת נראה כיצד Gradient Descent מטפל בפונקציות עם 2 משתנים!",

        "steps":"נציג למטה באנימציה את עשרת הצעדים הראשוניים של האלגוריתם:",
        "how":"איך האלגוריתם משיג זאת?",
        "defs":"הגדרות:",
        "almost_descr":"בצורה ממש דומה כמו קודם!",

        "point_vals":{
            "x_val":"את ערך x של הנקודה.",
            "y_val":"את ערך y של הנקודה.",
            "x_val_new":"את ערך x של הנקודה החדשה.",
            "y_val_new":"את ערך y של הנקודה החדשה.",
            "z_val":"את ערך z של הנקודה."
        },

        "derivatives":{
            "description":"הנגזרת של הפונקציה f.",
            "derivative_val_x":"להיות ערך הנגזרת של הפונקציה בנקודה x.",
            "f_by_x":"הנגזרת החלקית של הפונקציה f לפי המשתנה x (תתיחס ל-y כמספר וגזור כרגיל).",
            "f_by_y":"הנגזרת החלקית של הפונקציה f לפי המשתנה y (תתיחס ל-x כמספר וגזור כרגיל).",
            "val_f_by_x":"הערך של הנגזרת החלקית של הפונקציה f לפי המשתנה x בנקודה (x, y).",
            "val_f_by_y":"הערך של הנגזרת החלקית של הפונקציה f לפי המשתנה y בנקודה (x, y)."
        },
        
        "hyperparameter":"ה-Hyper-parameter שמכתיב את גודל הצעד.",
        "foreach_step":"בכל שלב האלגוריתם עושה את הפעולות הבאות:",
        "calc":"חשב",
        "apply":"השם",

        "slides":{
            "alpha": "אלפא",
            "starting_point":"נקודת התחלה",
            "derivative":"הנגזרת של הפונקציה היא"
        },
        "tasks" : {
            "1d_int": "מבוא לחד-מימד",
            "1d_vis": "ויזואליזציה",
            "1d_sbs": "צעד אחר צעד",
            "1d_hyp": "היפר-פרמטר",
            "2d_int": "מבוא לדו-מימד",
            "2d_vis": "ויזואליזציה",
            "2d_sbs": "צעד אחר צעד",
            "2d_hyp": "היפר-פרמטר"
        },

        "enter_func":"הזינו פונקציה (יכולה להיות כל פונקציה שתרצו אבל המשתנה חייב להיות x), Hyper-Parameter וקבעו את נקודת ההתחלה.\nלחץ על כפתור ההפעלה כדי להתחיל את האנימציה, אתה יכול גם להשהות אותה ולהגדיל את הגרף על ידי לחיצה על כפתור ההשהיה או לנקות הכל באמצעות כפתור X.",
        "try_calc":"נסו לחשב את הערך של כל משתנה כפי שעושה האלגוריתם (2 נקודות עשרוניות).\nכל לחיצה על החץ תצייר את השלב הבא/הקודם",
        "search_alpha":"חפש את האלפא הטוב ביותר שמגיע למינימום בכמות הצעדים הקטנה ביותר.",
        "you_try":"נסה זאת בעצמך! בדיוק כמו קודם המשתנים חייבים להיות x ו-y.",
        "challenge":"אתגר את עצמך וחשב כל שלב באלגוריתם."
    },

    "logreg": {
        "tasks" : {
            "log_reg_step_1_title": "פתיח",
            "log_reg_step_2_title": "תרגיל 1",
            "log_reg_step_3_title": "בעזרת ווקטורים",
            "log_reg_step_4_title": "ריבוי דגימות",
            "log_reg_step_5_title": "אימון מודל",
            "log_reg_step_6_title": "צעד אחר צעד",
            "log_reg_step_7_title": "היפר-פרמטרים"
        },

        "pages": {
            "intro_title": "רגרסיה לוגסטית",
            "intro": {
                "description":"בעולם הסטטיסטיקה, מודל רגרסיה לוגסתית היינו מודל הסתברותי שתפקידו לסווג מאורע כלשהו, כמו האם הקבוצה הולכת לנציח או לא (הפלט שלו זה כן\\לא) וכו'...",
                "weights": "רגרסיה לוגסטית הינה אחד מאלגורתמי הסיווג. והפרמטרים לאלגוריתם זה היינם משקלים ",
                "num": " ומספר ",
                "vec": "הקלט למסווג היינו ווקטור של תכונות ",
                "y": "והמסווג יחשב ",
                "y_def": ", כאשר זו ההסתברות שהאוביקט שייך למאורע, החישוב שלנו יתבסס על הנוסחא הבאה:",
                "sigmoid_fun_def": "כך שפונקצית הסיגמואיד מוגדרת כהלן ",
                "cal_prob": "המסווג ינבא שהאוביקט שייך למאורע (כלומר יחזיר 1) אם ",
                "demo": "כעת ננסה להבין את הנאמר לעיל בעזרת דוגמא, בחר\\י את ערכי המשקלים, ערך התכונה ואת המספר הקבוע:",
                "example": "בגרף למטה תוכלו לראות את ערך הנקודה y",
                "task1": "בהינתן w = 111 ו b = 1, איזה ערך של x יגרום להסתברות להיות 0.5"
            },
            "ex1_title": "רגרסיה לוגסטית תרגיל 1",
            "ex1": {
                "line_1": "לאחר שלמדנו את הבסיס הקטן לאופי חישוב ההסתברות, נעשה תרגיל קטן.",
                "line_2": "נתונות לכם אוסף של תמונות כך שלכל תמונה ישנן שתי תכונות:",
                "red_avg": "ממוצע העוצמה של הצבע האדום בתמונה.",
                "blue_avg": "ממוצע העוצמה של הצבע הכחול בתמונה."
            },
            "vec_rep_title": "רגרסיה לוגסטית בעזרת ווקטורים",
            "vec_rep": {
                "expr": "הביטוי",
                "expr_simple": "ניתן להפשטה על ידי 2 ווקטורים ",
                "alg_calc": "כך שהחישוב של הרגרסיה הלוגסטית ניתן לבטא באופן הבא:",
                "sig_def": "כאשר פונקציית הסיגמואיד ניתנת על ידי",
                "y_calc": "המסווג ינבא שהאוביקט שייך למאורע (כלומר יחזיר 1) אם ",
                "demo": "כעת ננסה להבין את הנאמר לעיל בעזרת דוגמא, בחר\\י את ערכי המשקלים, ערכי התכונות השונים ואת המספר הקבוע:",
                "graph": "וזה הגרף שמתאר את המסווג :"
            },
            "multi_samples_title": "רגרסיה לוגסטית עם ריבוי דגימות",
            "multi_samples": {
                "intro": "עד כה למדנו איך המודל מסווג קלט יחיד (בעל תכונה אחת או יותר), כעת אנו נלמד איך ניתן לסווג יותר מדגימה אחת (שכל אחת תהיה בעלת תכונה אחת או יותר)!",
                "vectors": "במילים אחרות נלמד איך להמיר אוסף של ווקטורים ",
                "matrix": " אל \n מטריצה אחת ענקית ",
                "Y": " אשר תכיל את כל המידע (כל שורה בטבלה תהווה תכונות של דוגמה כלשהי), לאחר מכן נפעיל את פונקציה הסיגמואיד על כניסות המטריצה בכדי לחשב את ווקטור ",
                "pred": " שהוא ווקטור של ההחלטות עבור כל דגימה",
                "samples_num": "מספר הדגימות",
                "features_num": "מספר התכונות",
                "task": "בעמוד זה נקבל 3 דגימות כך שכל דגימה תהווה צבע בעזרת שלוש תכונות שהם ערכי ה-RGB, ונרצה לנבא אם הצבע היינו כחול או לא (m = 3, n = 3) - ",
                "weights": "ווקטור של משקלים (לכל תכונה יש משקל):",
                "b": "ערך המספר הקבוע:",
                "matrix_pres": "המידע יאוכלס במטריצה באופן הזה:",
                "sigmoid_cal": "אנו מחשבים\\מפעילים את פונקצית הסיגמואיד על המטריצה לפי המתכון הבא",
                "calculate": " חשב את ",
                "add_b": " הוסף את הקבוע b לכל אחת מכניסות המטריצה - ",
                "apply": " הפעל את פונקציית הסיגמואיד על כל אחת מכניסות המטריצה - ",
                "get_Y": " וקבל ",
                "by_checking": " יל ידי בדיקה אם "
            },
            "training_title": "אימון רגרסיה לוגסטית",
            "training": {
                "intro": "בעמוד זה אנו נלמד איך לבנות מודל של רגריסה לוגסטית (עד כה למדנו איך המודל מסווג אך לא למדנו איך יוצרים מודל) \n במלים אחרות נלמד איך למצוא את המשקלים והמספר הטובים ביותר!",
                "logReg_q": "קודם כל מה זה מודל של רגרסיה לוגסטית",
                "logReg_ans_p1": "מודל של רגרסיה לוגסטית יסומן על ידי ",
                "logReg_ans_p2": " כך ש- ",
                "logReg_ans_w": "ווקטור המשקלים של המודל ",
                "logReg_ans_b": " הקבוע של המודל ",
                "acc_q": "קודם כל איך ניתן למדוד דיוק מודל",
                "acc_ans": "פונקציית הספד הינה פונקציה אשר מחזירה לנו מספר שמעיד אם המודל הוא טוב או לא (מדויק או לא) \n ככל שהמספר קרוב יותר ל-0 אזי המודל שלנו יותר טוב (מדויק יותר) \n ככל שהמספר רחוק יותר מה-0 אזי המודל שלנו פחות טוב (פחות מדויק)",
                "consider": "נניח שיש לנו",
                "consider_x": " מטריצה שמכילה את אוסף הדגימות (m) ",
                "consider_w": " ווקטור המשקלים (n) ",
                "consider_b": " הקבוע",
                "consider_c": " הסיווג האמיתי של כל דגימה",
                "calc_y": "לאחר מכן נחשב את ווקטור הסיווגים",
                "prev": "כמו קודם",
                "after": "לאחר מכן נחשב את פונקציית ההפסד שלנו",
                "ci": " הסיווג האמיתי של הדגימה ה-i'ית ",
                "yi": " הניבוי של הדגימה ה-i'ית ",
                "ret_type": "פונקציה זו תחזיר לנו מספר שמעיד אם המודל שלנו מספיק טוב או לא",
                "trainModel_q": "למה אנו מתכוונים באימון מודל",
                "trainModel_ans": "כאשר אנו אומרים 'אימון המודל' אנו מתכוונים לתהליך שבו מקבלים מלא דגימות בצורת טבלה (כפי שהסברנו קודם) \n ומבצעים תהליך חישובי שבסופו נרצה לקבל את המשקלים והמספר הקבוע הטובים ביותר \n כך שימזערו את פונקצית ההפסד שלנו (יתנו לנו מודל מדויק ככל האפשר)",
                "above_inputs": "נניח שיש לנו את הקלט שנזכר לעיל",
                "additional_inputs": "בנוסף יש לנו את ההיפר-פרמטר מאלגוריתם ה-Gradiant Descent",
                "defs": "נגדיר כמה מושגים",
                "loss_def": "פונקציית ההפסד שנזכרה לעיל",
                "dwi_def": "הנגזרת של פונקצית ההפסד לפי המשקל ה-i, הסימון X_i מהווה העמודה ה-i'ית של המטריצה X",
                "dW_def": "הנגזרת של פונקצית ההפסד לפי כל המשקלים",
                "dbi_def": "הנגזרת של פונקצית ההפסד לפי הקבוע b על הדגימה ה-i'ית",
                "dB_def": "הנגזרת של פונקצית ההפסד לפי הקבוע b על כל הדגימות",
                "init": "אתחל את המשתנים הבאים",
                "init_w": "ווקטור המשקלים (משקל לכל תכונה)",
                "init_b": "הקבוע",
                "step": "בכל צעד של חישוב ה-gradiant descent אנו מבצעים את התהליך הבא",
                "step_calculate": "חשב",
                "step_apply": "בצע",
                "demo": "כעת ננסה זאת על ידי תרגילון, הכניסו את ערכי הדגימות ואת הסיווג שלהן",
                "demo_init": "האלגוריתם יאתחל את המשתנים הבאים",
                "demo_itr_res": "התוצאות אחרי איטרציה אחת",
                "demo_final_res": "התוצאות הסופיות"
            },
            "sbs_title": "אימון רגרסיה לוגסטית צעד אחר צעד",
            "sbs": {
                "task": "במשימה הזו אנו נבצע את שלבי אימון המודל צעד אחר צעד",
                "itr_num": "איטרציה מספר",
                "res": "תוצאות",
                "calc": "חישובים",
                "final_res": "תוצאות סופיות"
            },
            "hp_title": "איך היפר-פרמטרים משפיעים",
            "hp": {
                "intro": "במשימה הזו אנו נלמד על השפעת ההיפר-פרמטר ואת מספר האיטרציות על דיוק המודל שלנו\n נקח את מסד הנתונים שמכיל מידע על פרחי איריס, לכל דגימה יהינה התכונות הבאות:",
                "sp_length": "אורך גביע (ביחידות של ס\"מ)",
                "sp_width": "רוחב גביע (ביחידות של ס\"מ)",
                "pe_length": "אורך עלי כותרת (ביחידות של ס\"מ)",
                "pe_width": "רוחב עלי כותרת (ביחידות של ס\"מ)",
                "dataset": "המידע שלנו מכיל שלושה סוגים של פרח איריס (50 דגימות מכל סוג)",
                "setosa": "סיטוסה",
                "versicolor": "וורסיקולור",
                "virginica": "וורגיניקה",
                "task": "הכניסו את ערך האלפא הרצוי, את מספר האיטרציות ואחוז הפיצול של המידע לאוסף של אימון ואוסף של בדיקה\\n, וקבלו את דיוק המודל ואת התוצאות הסופיות, נסו למצוא את הקלט שיוביל לתוצאות טובות ביותר!",
                "itr_num": "מספר האיטרציות",
                "trn_per": "אחוז המידע שישומש עבור האימון",
                "mdl_acc": "דיוק",
                "mdl_loss": "הפסד"
            }
        }
    },

    "lr": {
        "tasks" : {
            "1d_int": "פתיח",
            "1d_vis": "דוגמא ראשונה",
            "p3_title": "מודל דינאמי",
            "p4_title": "תרגילים לפתרון האנליטי",
            "p5_title": "חישובים בעזרת Gradient Descent",
            "p6_title": "תרגיל Gradient Descent"
        },

        "title":"רגרסיה לינארית",
        "examples_set":"בהינתן קבוצה של m נקודות",
        "x_vals":"ערכים של המשתנה הבלתי תלוי",
        "y_vals":"ערכים של המשתנה התלוי",
        "description":"רגרסיה לינארית היא שיטה מתמטית למציאת הפרמטרים שמקשרים בין המשתנה הבלתי תלוי X והמשתנה התלוי Y \n בהנחה שהקשר ביניהם הוא לינארי \n נרצה למצוא את המודל והפרמטרים האופטימליים לנוסחה הבאה:",
        "opt_params":"איך למצוא את הפרמטרים האופטימליים למודל?",
        "min_params":"אנחנו בוחרים את הפרמטרים שמביאם למינימום את ה mean squared error loss",
        "defs":"כמה הגדרות ",
        "x_mean_val":"הממוצע של ערכי x",
        "y_mean_val":"הממוצע של ערכי y",
        "analytic_sol":"הפתרון האנליטי יהיה",
        "p2_desc":"בתרגיל הזה ננסה לחזות את ערכי הדירות ( במליוני שקלים) כתלות במספר החדרים שיש בדירה.\nהטבלה מכילה מידע לגבי מחירי הדירות. למטה יש את הפרמטרים המחושבים שמהם המודל מחשב \nאת הפרמטרים כדי לשערך את חיזוי המודל, פונקציית הרגרסיה ולבסוף את הגרף שמייצג את הפונקציה הזו.",
        "p3_desc":"הגיע הזמן לראות את אופן פעולת המודל. /n תוסיפו נקודות ותערכו את הערכים כרצונכם, תבחינו שערכי הפרמטרים משתנים בהתאם לערכים והם מחושבים לפי הנוסחאות שראינו קודם, שימו לב שגם פונקציית הרגרסיה שמייצגת את האופן בו המודל מבצע את החיזוי, מחושבת בהתאם לערכים האלה ואתם יכולים לראות את הגרף שלה גם.",
        "p4_desc":"עכשיו התור שלך! בהינתן טבלה לא מלאה של דוגמאות מדאטאבייס של פרחי האיריסים, X מייצג את האורך של עלה הגביע, Y מייצג את רוחב עלה הגביע של הפרח.\n המשימה שלך היא לחשב את הפרמטרים באופן שבו יתאימו לבניית המודל הנכון.\n למטה נתון המבנה הנכון צבוע בכחול והמודל שלכם המתאים לפרמטרים שחישבתם יופיע באדום.\n בהצלחה!"
    },

    "sign_in":{
        "login":"תתחבר",
        "forgot_pass":"שכחת סיסמה?",
        "sign_up":"אין לך משתמש? תירשם!"
    },

    "footer":{
        "made_by":"נעשה ע''י סטונדים מהטכניון!"
    },

    "list_items":{
        "sub_head":"Saved reports"
    },

    "task":"משימה"

}